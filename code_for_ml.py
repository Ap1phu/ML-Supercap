# -*- coding: utf-8 -*-
"""Code for ML

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1CCUuaoaeRD2r7ZAeFmymX7HsnhpvbC_T

## Import Relevant Libraries
"""

import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.pyplot as plt
from statistics import mean
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler,PolynomialFeatures
from sklearn.model_selection import KFold
from sklearn.linear_model import LinearRegression,Ridge
import seaborn as sns
from sklearn.metrics import r2_score
from sklearn.svm import SVR
from sklearn.metrics import mean_squared_error
from sklearn.gaussian_process import GaussianProcessRegressor,kernels

"""## Import Data"""

raw_csv_data_pd = pd.read_csv("https://raw.githubusercontent.com/Ap1phu/Data-Supcap/main/Preprocess%20Data%204%20June.csv?token=GHSAT0AAAAAAB4KCDBWO7OHSKQ7YPXSWNQWY4X45XA")
raw_csv_data = raw_csv_data_pd.to_numpy()
unscaled_inputs = raw_csv_data[:,0:-1]
targets_all = raw_csv_data[:,-1]
print(unscaled_inputs.shape)
print(targets_all.shape)

np.random.seed(42)
shuffled_indices=np.arange(targets_all.shape[0])
np.random.shuffle(shuffled_indices)
np.random.shuffle(shuffled_indices)
shuffled_inputs = unscaled_inputs[shuffled_indices]
shuffled_targets = targets_all[shuffled_indices]

"""##Hold out test set (split train and test)
Note: Validation split at k-fold
"""

samples_count = shuffled_inputs.shape[0]
train_samples_count = int(0.9 * samples_count)
train_inputs = shuffled_inputs[:train_samples_count]
train_targets = shuffled_targets[:train_samples_count]
test_inputs = shuffled_inputs[train_samples_count:]
test_targets = shuffled_targets[train_samples_count:]
print(test_inputs.shape)

"""##Scaler+PCA"""

def preprocess(train,validation,test):
  scaler=StandardScaler()
  scaler.fit(train)
  scaled_train_inputs=scaler.transform(train)
  scaled_validation_inputs=scaler.transform(validation)
  scaled_test_inputs=scaler.transform(test)
  X,Y,Z = pca_scale(scaled_train_inputs,scaled_validation_inputs,scaled_test_inputs)
  return X,Y,Z

def pca_scale(train,validation,test):
  pca=PCA(n_components = 9)
  reduced_train_inputs=pca.fit_transform(train)
  reduced_validation_inputs=pca.transform(validation)
  reduced_test_inputs=pca.transform(test)
  return reduced_train_inputs,reduced_validation_inputs,reduced_test_inputs

"""##Show Performance Function"""

def perform(train_val_acc,pred_train,pred_test):
  print("R-square on train is",train_val_acc[:,0])
  print("R-square on validation is",train_val_acc[:,1])
  print("RMSE on train is", (1-train_val_acc[:,0])*TSS[:,0])
  print("RMSE on validation is", (1-train_val_acc[:,1])*TSS[:,1])
  print("Average R-square on train is",np.mean(train_val_acc,axis=0)[0],"Average R-square on validation is",np.mean(train_val_acc,axis=0)[1])
  print("R-square on test set is",r2_score(test_targets,np.mean(pred_test,axis=1)))
  print("RMSE on test set is", mean_squared_error(test_targets,np.mean(pred_test,axis=1)))
  plt.scatter(np.squeeze(np.mean(pred_train,axis=1)),np.squeeze(train_targets),s=20)
  plt.scatter(np.squeeze(np.mean(pred_test,axis=1)),np.squeeze(test_targets),c='red',s=20)
  plt.plot(shuffled_targets,shuffled_targets,c='orange')
  plt.xlabel("Predicted value (F/g)", fontsize=18)
  plt.ylabel("Experimental value(F/g)", fontsize=18)
  plt.xlim([0,400])
  plt.ylim([-10,400])
  plt.show()

"""##LR+CV"""

def LR(X_train,y_train,X_validation,y_validation,X_test,i):   #Model must update train_val_acc,pred_train,pred_test
  #Model
  reg=LinearRegression()
  reg.fit(X_train,y_train)
  #Predict and Evaluate
  train_val_acc[i,:]=np.array([reg.score(X_train,y_train),reg.score(X_validation,y_validation)])
  pred_train[:,i]=reg.predict(np.insert(X_train,validation_index[0],X_validation,axis=0))   #Unmix the pred_train for plotting
  pred_test[:,i]=reg.predict(X_test)

#Initiate some arrays
k , i = 10 , 0
kf = KFold(n_splits=k)
pred_train , pred_test = np.zeros((train_inputs.shape[0],k)) , np.zeros((test_inputs.shape[0],k)) 
train_val_acc , TSS =np.zeros((k,2)) , np.zeros((k,2))

#Split,CV,Preprocess
for train_index, validation_index in kf.split(train_targets):
  X_train, X_validation = train_inputs[train_index], train_inputs[validation_index]
  y_train, y_validation = train_targets[train_index], train_targets[validation_index]
  Test=test_inputs
  X_train_prep, X_validation_prep, X_test_prep = preprocess(X_train, X_validation,Test)
  TSS[i,0]=np.mean((y_train-np.mean(y_train))**2)
  TSS[i,1]=np.mean((y_validation-np.mean(y_validation))**2)

  #Model Here
  LR(X_train_prep,y_train,X_validation_prep,y_validation,X_test_prep,i)
  i+=1
#Show Performance
perform(train_val_acc,pred_train,pred_test)

"""##ANN+L2+CV"""

def PlotLC(Learning_curve):
  #np.save(F"/content/drive/MyDrive/ANN Model/3Learning_curve", Learning_curve)
  loss , val_loss = Learning_curve[:,0] , Learning_curve[:,1]
  indices=np.linspace(1,Learning_curve.shape[0],num=Learning_curve.shape[0])
  plt.plot(indices,loss,c='orange')
  plt.plot(indices,val_loss,c='purple')
  plt.xlabel("Iterations", fontsize=18)
  plt.ylabel("Loss", fontsize=18)
  plt.xlim([0,Learning_curve.shape[0]])
  plt.ylim([0,5000])
  plt.show()

def ANN(X_train,y_train,X_validation,y_validation,X_test,i,Learning_curve):
  #Model
  input_size = 9
  output_size = 1
  hidden_layer_size_1 = 30
  max_epochs = 300
  model = tf.keras.Sequential([
        tf.keras.layers.Dense(hidden_layer_size_1, activation='tanh',kernel_regularizer=tf.keras.regularizers.L2(0.01)), # 1st hidden layer
        tf.keras.layers.Dense(output_size, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.01)) # output layer
    ])
  lr_schedule=0.1
  customized_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)
  model.compile(optimizer=customized_optimizer, loss='mse', metrics=['mean_squared_error'])
  history=model.fit(X_train, # train inputs
            y_train, # train targets
            epochs=max_epochs, # epochs that we will train for
            validation_data=(X_validation, y_validation), # validation data
            verbose = 0 # making sure we get enough information about the training process 2 is reporting everything
            )
    
  #Predict and Evaluate
  train_val_acc[i,:]=np.array([r2_score(y_train,model.predict(X_train)),r2_score(y_validation,model.predict(X_validation))])
  pred_train[:,i]=model.predict(np.insert(X_train,validation_index[0],X_validation,axis=0)).reshape(-1,)
  pred_test[:,i]=model.predict(X_test).reshape(-1,)

  #Save model
  #filepath = F"/content/drive/MyDrive/ANN Model/3Fold"+str(i)    
  #tf.keras.models.save_model(model,filepath)
  print(i)
  
  #For Learning Curve
  if np.all(Learning_curve)==0:
    Learning_curve=np.ones((max_epochs,2,k)) #2 for train and val loss
  Learning_curve[:,0,i]=history.history['loss'] 
  Learning_curve[:,1,i]=history.history['val_loss']
  return Learning_curve

#Initiate some arrays
k , i , Learning_curve = 10 , 0 , 0
kf = KFold(n_splits=k)
pred_train , pred_test = np.zeros((train_inputs.shape[0],k)) , np.zeros((test_inputs.shape[0],k)) 
train_val_acc=np.zeros((k,2))

#Split,CV,Preprocess
for train_index, validation_index in kf.split(train_targets):
  X_train, X_validation = train_inputs[train_index], train_inputs[validation_index]
  y_train, y_validation = train_targets[train_index], train_targets[validation_index]
  Test=test_inputs
  X_train_prep, X_validation_prep, X_test_prep = preprocess(X_train, X_validation,Test)

  #Model Here
  Learning_curve=ANN(X_train_prep,y_train,X_validation_prep,y_validation,X_test_prep,i,Learning_curve)
  i+=1

#Show Performance
perform(train_val_acc,pred_train,pred_test)
PlotLC(np.mean(Learning_curve,axis=2))

"""##SVR+CV"""

def SVM(X_train,y_train,X_validation,y_validation,X_test,i,C=500):   #Model must update train_val_acc,pred_train,pred_test
  #Model
  reg=SVR(kernel='rbf', C=C, epsilon=15.0)
  reg.fit(X_train,y_train)
  #Predict and Evaluate
  train_val_acc[i,:]=np.array([reg.score(X_train,y_train),reg.score(X_validation,y_validation)])
  pred_train[:,i]=reg.predict(np.insert(X_train,validation_index[0],X_validation,axis=0))   #Unmix the pred_train for plotting
  pred_test[:,i]=reg.predict(X_test)

#Initiate some arrays
k , i = 10 , 0
kf = KFold(n_splits=k)
pred_train , pred_test = np.zeros((train_inputs.shape[0],k)) , np.zeros((test_inputs.shape[0],k)) 
train_val_acc=np.zeros((k,2))

#Split,CV,Preprocess
for train_index, validation_index in kf.split(train_targets):
  X_train, X_validation = train_inputs[train_index], train_inputs[validation_index]
  y_train, y_validation = train_targets[train_index], train_targets[validation_index]
  Test=test_inputs
  X_train_prep, X_validation_prep, X_test_prep = preprocess(X_train, X_validation,Test)

  #Model Here
  SVM(X_train_prep,y_train,X_validation_prep,y_validation,X_test_prep,i)
  i+=1
#Show Performance
perform(train_val_acc,pred_train,pred_test)

np.mean(pred_test,axis=1)

"""Choosing C and epsilon (End up choosing epsilon=15, C=500)"""

#Initiate some arrays
Performance=np.zeros((700,2))
j , CBest , PerformBest= 0 , 0 , 0
for C in range(1,701):
  k , i = 10 , 0
  kf = KFold(n_splits=k)
  pred_train , pred_test = np.zeros((train_inputs.shape[0],k)) , np.zeros((test_inputs.shape[0],k)) 
  train_val_acc=np.zeros((k,2))
  #Split,CV,Preprocess
  for train_index, validation_index in kf.split(train_targets):
    X_train, X_validation = train_inputs[train_index], train_inputs[validation_index]
    y_train, y_validation = train_targets[train_index], train_targets[validation_index]
    Test=test_inputs
    X_train_prep, X_validation_prep, X_test_prep = preprocess(X_train, X_validation,Test)

    #Model Here
    SVM(X_train_prep,y_train,X_validation_prep,y_validation,X_test_prep,i,C)
    i+=1
  #Show Performance
  Performance[j,:]=np.mean(train_val_acc,axis=0)
  if Performance[j,:][1]>PerformBest+0.01:  #Set to 0.01 sensitivity 
    CBest=C
    PerformBest=Performance[j,:][1]
  j+=1
print(Performance.shape)
loss , val_loss = Performance[:,0] , Performance[:,1]
indices=np.linspace(1,700,num=700)
plt.plot(indices,loss,c='orange')
plt.plot(indices,val_loss,c='purple')
plt.xlabel("R-square", fontsize=18)
plt.ylabel("C", fontsize=18)
plt.xlim([1,700])
plt.ylim([0,1.0])
plt.show() 
print("C that gives the highest on average validation set is",CBest)
print("Best val performance is",PerformBest)

"""##Deep NN+CV+L2"""

def DNN(X_train,y_train,X_validation,y_validation,X_test,i,Learning_curve):
  #Model
  input_size = 9
  output_size = 1
  hidden_layer_size_1 = 30
  hidden_layer_size_2 = 30
  max_epochs = 500
  model = tf.keras.Sequential([
        tf.keras.layers.Dense(hidden_layer_size_1, activation='tanh',kernel_regularizer=tf.keras.regularizers.L2(0.01)), # 1st hidden layer
        tf.keras.layers.Dense(hidden_layer_size_2, activation='tanh',kernel_regularizer=tf.keras.regularizers.L2(0.01)), # 2nd hidden layer
        tf.keras.layers.Dense(output_size, activation='relu',kernel_regularizer=tf.keras.regularizers.L2(0.01)) # output layer
    ])
  lr_schedule=0.1
  customized_optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)
  model.compile(optimizer=customized_optimizer, loss='mse', metrics=['mean_squared_error'])
  history=model.fit(X_train, # train inputs
            y_train, # train targets
            epochs=max_epochs, # epochs that we will train for
            validation_data=(X_validation, y_validation), # validation data
            verbose = 0 # making sure we get enough information about the training process 2 is reporting everything
            )
    
  #Predict and Evaluate
  train_val_acc[i,:]=np.array([r2_score(y_train,model.predict(X_train)),r2_score(y_validation,model.predict(X_validation))])
  pred_train[:,i]=model.predict(np.insert(X_train,validation_index[0],X_validation,axis=0)).reshape(-1,)
  pred_test[:,i]=model.predict(X_test).reshape(-1,)

  #Save model
  #filepath = F"/content/drive/MyDrive/ANN Model/3Fold"+str(i)    
  #tf.keras.models.save_model(model,filepath)
  print(i)
  
  #For Learning Curve
  if np.all(Learning_curve)==0:
    Learning_curve=np.ones((max_epochs,2,k)) #2 for train and val loss
  Learning_curve[:,0,i]=history.history['loss'] 
  Learning_curve[:,1,i]=history.history['val_loss']
  return Learning_curve

#Initiate some arrays
k , i , Learning_curve = 10 , 0 , 0
kf = KFold(n_splits=k)
pred_train , pred_test = np.zeros((train_inputs.shape[0],k)) , np.zeros((test_inputs.shape[0],k)) 
train_val_acc=np.zeros((k,2))

#Split,CV,Preprocess
for train_index, validation_index in kf.split(train_targets):
  X_train, X_validation = train_inputs[train_index], train_inputs[validation_index]
  y_train, y_validation = train_targets[train_index], train_targets[validation_index]
  Test=test_inputs
  X_train_prep, X_validation_prep, X_test_prep = preprocess(X_train, X_validation,Test)

  #Model Here
  Learning_curve=DNN(X_train_prep,y_train,X_validation_prep,y_validation,X_test_prep,i,Learning_curve)
  i+=1

#Show Performance
perform(train_val_acc,pred_train,pred_test)
PlotLC(np.mean(Learning_curve,axis=2))

"""##GPR+CV"""

def GPR(X_train,y_train,X_validation,y_validation,X_test,i):   #Model must update train_val_acc,pred_train,pred_test
  #Model
  gpr=GaussianProcessRegressor(alpha=10,kernel=kernels.ConstantKernel(1.0, constant_value_bounds=(1e-5,10000000)) * kernels.RBF(1.0, length_scale_bounds="fixed"),n_restarts_optimizer=2)
  gpr.fit(X_train,y_train)
  log_marg[:,i]=np.array([gpr.log_marginal_likelihood()])
  #Predict and Evaluate
  train_val_acc[i,:]=np.array([gpr.score(X_train,y_train),gpr.score(X_validation,y_validation)])
  pred_train[:,i]=gpr.predict(np.insert(X_train,validation_index[0],X_validation,axis=0))   #Unmix the pred_train for plotting
  pred_test[:,i]=gpr.predict(X_test)

#Initiate some arrays
k , i = 10 , 0
kf = KFold(n_splits=k)
pred_train , pred_test = np.zeros((train_inputs.shape[0],k)) , np.zeros((test_inputs.shape[0],k)) 
train_val_acc , TSS = np.zeros((k,2)) , np.zeros((k,2))
log_marg = np.zeros((1,k))

#Split,CV,Preprocess
for train_index, validation_index in kf.split(train_targets):
  X_train, X_validation = train_inputs[train_index], train_inputs[validation_index]
  y_train, y_validation = train_targets[train_index], train_targets[validation_index]
  Test=test_inputs
  X_train_prep, X_validation_prep, X_test_prep = preprocess(X_train, X_validation,Test)
  TSS[i,0]=np.mean((y_train-np.mean(y_train))**2)
  TSS[i,1]=np.mean((y_validation-np.mean(y_validation))**2)

  #Model Here
  GPR(X_train_prep,y_train,X_validation_prep,y_validation,X_test_prep,i)
  i+=1
#Show Performance
perform(train_val_acc,pred_train,pred_test)
print(np.mean(log_marg,axis=1))

"""##GLR+CV"""

def GLR(X_train,y_train,X_validation,y_validation,X_test,i):   #Model must update train_val_acc,pred_train,pred_test
  #Model
  #reg=LinearRegression()
  reg=Ridge(alpha=10.0)
  reg.fit(X_train,y_train)
  coef[:,i]=reg.coef_
  #Predict and Evaluate
  train_val_acc[i,:]=np.array([reg.score(X_train,y_train),reg.score(X_validation,y_validation)])
  pred_train[:,i]=reg.predict(np.insert(X_train,validation_index[0],X_validation,axis=0))   #Unmix the pred_train for plotting
  pred_test[:,i]=reg.predict(X_test)

#Initiate some arrays
k , i = 10 , 0
kf = KFold(n_splits=k)
pred_train , pred_test = np.zeros((train_inputs.shape[0],k)) , np.zeros((test_inputs.shape[0],k)) 
train_val_acc , TSS =np.zeros((k,2)) , np.zeros((k,2))
coef = np.zeros((55,k))

#Split,CV,Preprocess
for train_index, validation_index in kf.split(train_targets):
  X_train, X_validation = train_inputs[train_index], train_inputs[validation_index]
  y_train, y_validation = train_targets[train_index], train_targets[validation_index]
  Test = test_inputs
  X_train_prep, X_validation_prep, X_test_prep = preprocess(X_train, X_validation,Test)
  poly = PolynomialFeatures(degree=2)
  poly_train_inputs=poly.fit_transform(X_train_prep)
  poly_validation_inputs=poly.transform(X_validation_prep)
  poly_test_inputs=poly.transform(X_test_prep)
  TSS[i,0]=np.mean((y_train-np.mean(y_train))**2)
  TSS[i,1]=np.mean((y_validation-np.mean(y_validation))**2)

    #Model Here
  GLR(poly_train_inputs,y_train,poly_validation_inputs,y_validation,poly_test_inputs,i)
  i+=1
  #Show Performance
perform(train_val_acc,pred_train,pred_test)

np.mean(pred_test,axis=1)

